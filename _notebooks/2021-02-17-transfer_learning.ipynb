{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Transfer Learning\"\n",
    "> \"How to reuse knowledge infused in a model to perform a similar yet slightly different task\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [en, ml, raw]\n",
    "- hide: true\n",
    "- search_exclude: false\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "\n",
    "from keras.models import Sequential\n",
    "import cv2\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "import pandas as pd\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "\n",
    "from pathlib import Path\n",
    "mnist_path = Path(\"mnist\")\n",
    "img_path = Path(\"mnist/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset from scikit learn dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797 1347 range(0, 1347) range(1347, 1797)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "for i, im in enumerate(digits['images']):\n",
    "    cv2.imwrite(Path.joinpath(img_path, f\"{i}.png\").as_posix(),im*16)\n",
    "\n",
    "(pd.DataFrame({\"labels\": digits[\"target\"]})\n",
    " .to_csv(Path.joinpath(img_path, \"labels.csv\").as_posix())\n",
    ")\n",
    "\n",
    "nb_img = len(list(img_path.glob('*.png')))\n",
    "limit = int(nb_img*0.75)\n",
    "train_range = range(limit)\n",
    "test_range = range(limit, nb_img)\n",
    "print(nb_img, limit, train_range, test_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "train_img=[]\n",
    "for i in train_range:\n",
    "    temp_img=image.load_img(\n",
    "        Path.joinpath(img_path, f\"{i}.png\").as_posix(),\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "    train_img.append(temp_img)\n",
    "\n",
    "#converting train images to array and applying mean subtraction processing\n",
    "\n",
    "train_img=np.array(train_img)\n",
    "train_img=preprocess_input(train_img)\n",
    "# applying the same procedure with the test dataset\n",
    "\n",
    "test_img=[]\n",
    "for i in test_range:\n",
    "    temp_img=image.load_img(\n",
    "        Path.joinpath(img_path, f\"{i}.png\").as_posix(),\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "    temp_img=image.img_to_array(temp_img)\n",
    "    test_img.append(temp_img)\n",
    "\n",
    "test_img=np.array(test_img)\n",
    "test_img=preprocess_input(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# loading VGG16 model weights\n",
    "transferred_model = VGG16(weights='imagenet', include_top=False)\n",
    "transferred_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1347, 7, 7, 512) (450, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "re_extract_features = False\n",
    "if re_extract_features:\n",
    "    # Extracting features from the train dataset using the VGG16 pre-trained model\n",
    "    features_train=transferred_model.predict(train_img)\n",
    "    # Extracting features from the train dataset using the VGG16 pre-trained model\n",
    "    features_test=transferred_model.predict(test_img)\n",
    "else:\n",
    "    import h5py\n",
    "    with h5py.File(\"mnist/mnist_features.hdf5\", \"r\") as f:\n",
    "        features_train = np.array(f[\"features/train\"])\n",
    "        features_test = np.array(f[\"features/test\"])\n",
    "        print(features_train.shape, features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the model and the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1347, 7, 7, 512), (450, 7, 7, 512))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape, features_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"mnist/mnist_features.hdf5\", \"w\") as f:\n",
    "    dset_train = f.create_dataset(\"features/train\", data=features_train)\n",
    "    dset_test = f.create_dataset(\"features/test\", data=features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Ajouter une phase de mise en évidence des features #explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt features to new MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      labels\n",
       "0          0\n",
       "1          1\n",
       "2          2\n",
       "3          3\n",
       "4          4\n",
       "...      ...\n",
       "1792       9\n",
       "1793       0\n",
       "1794       8\n",
       "1795       9\n",
       "1796       8\n",
       "\n",
       "[1797 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(Path.joinpath(img_path, \"labels.csv\").as_posix(), index_col=0)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (1347, 25088) (1347, 10)\n",
      "Testing set (450, 25088) (450, 10)\n"
     ]
    }
   ],
   "source": [
    "# flattening the layers to conform to MLP input (N, 7, 7, 512) --> (N, 25088)\n",
    "train_x=features_train.reshape(features_train.shape[0], 25088)\n",
    "\n",
    "# converting target variable to array\n",
    "train_y=labels[\"labels\"].values[train_range]\n",
    "# performing one-hot encoding for the target variable\n",
    "train_y=pd.get_dummies(train_y)\n",
    "train_y=np.array(train_y)\n",
    "# creating training and validation set\n",
    "print(\"Training set\", train_x.shape, train_y.shape)\n",
    "\n",
    "# flattening the layers to conform to MLP input (N, 7, 7, 512) --> (N, 25088)\n",
    "test_x=features_test.reshape(features_test.shape[0], 25088)\n",
    "\n",
    "# converting target variable to array\n",
    "test_y=labels[\"labels\"].values[test_range]\n",
    "# performing one-hot encoding for the target variable\n",
    "test_y=pd.get_dummies(test_y)\n",
    "test_y=np.array(test_y)\n",
    "# creating testing and validation set\n",
    "print(\"Testing set\", test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(1000, input_dim=25088, activation='relu',kernel_initializer='uniform'))\n",
    "keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(500,input_dim=1000,activation='sigmoid'))\n",
    "keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(150,input_dim=500,activation='sigmoid'))\n",
    "keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)\n",
    "\n",
    "model.add(Dense(units=10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 2s 117ms/step - loss: 2.3253 - accuracy: 0.1903 - val_loss: 1.8503 - val_accuracy: 0.7089\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 1.7412 - accuracy: 0.7974 - val_loss: 1.3985 - val_accuracy: 0.8378\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 1.2646 - accuracy: 0.9024 - val_loss: 0.9943 - val_accuracy: 0.9289\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.8349 - accuracy: 0.9636 - val_loss: 0.6862 - val_accuracy: 0.9378\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.5149 - accuracy: 0.9812 - val_loss: 0.4834 - val_accuracy: 0.9422\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 1s 104ms/step - loss: 0.3083 - accuracy: 0.9904 - val_loss: 0.3589 - val_accuracy: 0.9356\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.1978 - accuracy: 0.9961 - val_loss: 0.2829 - val_accuracy: 0.9489\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.1226 - accuracy: 0.9994 - val_loss: 0.2266 - val_accuracy: 0.9533\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9556\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9578\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9578\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9622\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 1s 103ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9578\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9622\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 1s 105ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9600\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9556\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9578\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9578\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 1s 102ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9578\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 1s 101ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17045cb20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_x,test_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True, False,  True, ..., False, False, False],\n",
       "       [False,  True, False, ..., False, False, False],\n",
       "       [ True, False,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True, False,  True],\n",
       "       [False, False, False, ..., False,  True, False],\n",
       "       [False, False, False, ...,  True, False,  True]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predict_y, axis=1) == labels.values[test_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2: append new layers and freeze bottom layers of VGG for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "# Creating dictionary that maps layer names to the layers\n",
    "layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers])\n",
    "\n",
    "# Getting output tensor of the last VGG layer that we want to include\n",
    "x = layer_dict['block5_pool'].output\n",
    "\n",
    "# Adding new layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(1000, input_dim=25088, activation='relu',kernel_initializer='uniform')(x)\n",
    "x = keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)(x)\n",
    "x = Dense(500,input_dim=1000,activation='sigmoid')(x)\n",
    "x = keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)(x)\n",
    "x = Dense(150,input_dim=500,activation='sigmoid')(x)\n",
    "x = keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)(x)\n",
    "x = Dense(units=10)(x)\n",
    "x = Activation('softmax')(x)\n",
    "\n",
    "\n",
    "# Creating new model. Please note that this is NOT a Sequential() model.\n",
    "from keras.models import Model\n",
    "custom_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "\n",
    "# Make sure that the pre-trained bottom layers are not trainable\n",
    "for layer in custom_model.layers:\n",
    "    if layer.name in layer_dict:\n",
    "        layer.trainable = False\n",
    "\n",
    "# Do not forget to compile it\n",
    "custom_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1000)              25089000  \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 150)               75150     \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                1510      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 40,380,848\n",
      "Trainable params: 25,666,160\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 122s 11s/step - loss: 2.4470 - accuracy: 0.1130 - val_loss: 2.1486 - val_accuracy: 0.2711\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 136s 13s/step - loss: 2.2192 - accuracy: 0.1839 - val_loss: 1.9199 - val_accuracy: 0.6311\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 129s 12s/step - loss: 1.9635 - accuracy: 0.3612 - val_loss: 1.4907 - val_accuracy: 0.7600\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 128s 12s/step - loss: 1.5639 - accuracy: 0.6354 - val_loss: 1.0121 - val_accuracy: 0.8244\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 128s 12s/step - loss: 1.0947 - accuracy: 0.7856 - val_loss: 0.6528 - val_accuracy: 0.8978\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 618s 61s/step - loss: 0.7248 - accuracy: 0.8800 - val_loss: 0.4142 - val_accuracy: 0.9244\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 124s 12s/step - loss: 0.4343 - accuracy: 0.9431 - val_loss: 0.3164 - val_accuracy: 0.9244\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 127s 12s/step - loss: 0.2650 - accuracy: 0.9688 - val_loss: 0.2276 - val_accuracy: 0.9467\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 0.1566 - accuracy: 0.9865 - val_loss: 0.1752 - val_accuracy: 0.9600\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 146s 13s/step - loss: 0.1018 - accuracy: 0.9874 - val_loss: 0.2028 - val_accuracy: 0.9511\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 138s 13s/step - loss: 0.0771 - accuracy: 0.9946 - val_loss: 0.1748 - val_accuracy: 0.9511\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 137s 13s/step - loss: 0.0557 - accuracy: 0.9978 - val_loss: 0.1440 - val_accuracy: 0.9600\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 137s 13s/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9533\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 0.0300 - accuracy: 0.9993 - val_loss: 0.1574 - val_accuracy: 0.9578\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9511\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 132s 12s/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9578\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9600\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 133s 12s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9489\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 131s 12s/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9578\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 126s 12s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1741d5160>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.fit(\n",
    "    train_img,\n",
    "    train_y,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_img,test_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model.save(\"mnist/custom_model.h5\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = keras.models.load_model(\"mnist/custom_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARXklEQVR4nO3dfYxV9Z3H8fdHEHwWKS5BoAKGNuJmHS2ISVV82LZqNgX2DxezUezqookmmnSzQU12zSZNut2qabO7NhiN2Pi4qxT+oLsiNpom4hOliIKKFCLjCC3Kg4iUh+/+cX5Tr8PMMsy595w7/D6vZDL3/u6Z+X5vrnw859w756uIwMzydUzdDZhZvRwCZplzCJhlziFgljmHgFnmHAJmmWtZCEi6UtI7ktZLmt+qOmZWjlrxOQFJQ4B3gW8Bm4HXgGsj4u2mFzOzUlq1J3ABsD4iNkTEH4EngZktqmVmJQxt0e8dC3zQcH8zML2vjSUdlR9bHDFiBCNGjKikliSOP/74SmpFBNu3b6+kFsC2bds4cOBAJbUOHjzIUfwp2j9ExOk9F1sVAoclaR4wr676VbjsssuYObOaHaDhw4dz9tlnV1IrIli8eHEltQAeeeSRykJnz5497N27t5JaNdjU22KrQqATGN9wf1xa+5OIWAAsgKN3T8BsMGjVOYHXgMmSJkoaBswBlrSolpmV0JI9gYjYL+k24H+BIcDDEfFWK2qZWTktOycQEUuBpa36/WbWHP7EoFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGVuwCEgabykX0l6W9Jbkm5P6/dI6pS0Kn1d3bx2zazZylxUZD/w/YhYKelk4A1Jy9Jj90fEj8u3Z2atNuAQiIguoCvd3iVpLcWlxs1sEGnKOQFJE4DzgFfS0m2SVkt6WNJpzahhZq1ROgQknQQ8A9wRETuBB4CzgA6KPYV7+/i5eZJel/R62R7MbOBKhYCkYykC4LGIeBYgIrZExIGIOAg8SDGS7BARsSAipkbE1DI9mFk5Az4nIEnAQ8DaiLivYX1MOl8AMBtYU67Fwevss89m1qxZldSSxLBhwyqpBTBu3LjKakni448/rqTWyy+/zKuvvlpJrXZR5t2BbwLXAW9KWpXW7gKuldQBBLARuLlEjUFt+PDhnHrqqXW30RLHHXdcZbVGjhxZ2XzAKp9Xuyjz7sCvAfXykGcNmA0i/sSgWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJa5MlcWAkDSRmAXcADYHxFTJY0EngImUFxd6JqI+KRsLTNrvmbtCVwWER0NFw2dDyyPiMnA8nTfzNpQqw4HZgIL0+2FwKwW1TGzkpoRAgE8J+kNSfPS2uiGKw5/BIzu+UOeO2DWHkqfEwAuiohOSX8GLJO0rvHBiAhJh1wqNiIWAAsAenvczKpRek8gIjrT963AIophI1skjYFiDgGwtWwdM2uNshOITkwTiZF0IvBtimEjS4C5abO5wOIydcysdcoeDowGFhXDiBgKPB4R/yPpNeBpSTcCm4BrStYxsxYpFQIRsQE4t5f1bcAVZX730WDt2rUsWrSoklp79+5lw4YNldQCmD17dmW1oLrJQEOHNuM02eCS3zOu0Lp161iyZEkltXbu3MkLL7xQSS2AKVOmkPYAW06SQ6CF/LFhs8w5BMwy5xAwy5xDwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwyN+C/m5T0dYrZAt0mAf8EjAD+Hvh9Wr8rIpYOtI6ZtdaAQyAi3gE6ACQNAToprjH4PeD+iPhxMxo0s9Zq1uHAFcD7EbGpSb/PzCrSrBCYAzzRcP82SaslPSzptCbVMLMWKB0CkoYB3wX+Ky09AJxFcajQBdzbx895+IhZG2jGnsBVwMqI2AIQEVsi4kBEHAQepJhDcIiIWBARUxvmF5pZDZoRAtfScCjQPXQkmU0xh8DM2lSpS6umgSPfAm5uWP6RpA6KGYUbezxmZm2m7NyB3cBXeqxdV6ojM6uUPzFoljmHgFnm8hu3UqHPP/+c7du3V1Jr9+7dHDhwoJJaAMOGDausVkRU9twiopI67cQh0ELr1q1j3bp1dbfREmeccUZlY8jWrl3Lp59+WkmtvXv3VlKnnfhwwCxzDgGzzDkEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8w5BMwy168QSBcM3SppTcPaSEnLJL2Xvp+W1iXpp5LWp4uNnt+q5s2svP7uCTwCXNljbT6wPCImA8vTfSiuOTg5fc2juPCombWpfoVARLwEfNxjeSawMN1eCMxqWH80CiuAET2uO2hmbaTMOYHREdGVbn8EjE63xwIfNGy3Oa2ZWRtqyvUEIiIkHdHVGCTNozhcMLMaldkT2NK9m5++b03rncD4hu3GpbUv8dwBs/ZQJgSWAHPT7bnA4ob169O7BBcCOxoOG8yszfTrcEDSE8ClwChJm4F/Bn4IPC3pRmATcE3afClwNbAe+IxiSrGZtal+hUBEXNvHQ1f0sm0At5Zpysyq408MmmXOIWCWOYeAWeYcAmaZcwiYZc4TiGxAqpo+1C3H8WBVcQgcJU4++WQuv/zySmpJ4swzz6ykFsDKlSv58MMPK6m1adOmSuq0E4fAUaTq/ztXXc9aw+cEzDLnEDDLnEPALHMOAbPMOQTMMucQMMucQ8Ascw4Bs8wdNgT6GDzyb5LWpeEiiySNSOsTJO2RtCp9/ayFvZtZE/RnT+ARDh08sgz484j4C+Bd4M6Gx96PiI70dUtz2jSzVjlsCPQ2eCQinouI/enuCoorCpvZINSMcwJ/B/yy4f5ESb+R9KKki/v6IUnzJL0u6fUm9GBmA1TqD4gk3Q3sBx5LS13AVyNim6RvAL+QdE5E7Oz5sxGxAFiQfo//TtSsJgPeE5B0A/BXwN+mKwwTEXsjYlu6/QbwPvC1JvRpZi0yoBCQdCXwj8B3I+KzhvXTJQ1JtydRTCbe0IxGzaw1Dns40MfgkTuB4cCy9DflK9I7AZcA/yJpH3AQuCUiek4zNrM2ctgQ6GPwyEN9bPsM8EzZpsysOv7EoFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5TyBqoenTpzNt2rRKao0aNYqbbrqpkloAy5cvr6zWihUr6OrqqqTWvn37KqnTThwCLXTCCScwatSoSmqNGjWKsWPHVlIrIvj0008rqQXw2WefsWfPnsrq5caHA2aZcwiYZc4hYJY5h4BZ5hwCZpkb6NyBeyR1NswXuLrhsTslrZf0jqTvtKpxM2uOgc4dALi/Yb7AUgBJU4A5wDnpZ/6z+3JjZtaeBjR34P8xE3gyXXD0d8B64IIS/ZlZi5U5J3BbGkP2sKTT0tpY4IOGbTantUN47oBZexhoCDwAnAV0UMwauPdIf0FELIiIqRExdYA9mFkTDCgEImJLRByIiIPAg3yxy98JjG/YdFxaM7M2NdC5A2Ma7s4Gut85WALMkTRc0kSKuQOvlmvRzFppoHMHLpXUAQSwEbgZICLekvQ08DbFeLJbI+JASzo3s6Zo6tyBtP0PgB+UacrMquNPDJplziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5rKbQDR9+nROOOGESmpdeumlzJgxo5JaVT2nbh0dHZXVuv3229m1a1cltVavXs2aNWsOv2ET7Nu3j87O+v/SPrsQmDZtWmWjwWbMmFFZCFRJEueee25l9SZNmsTBgwcrqfX4449XNmJt9+7dbRECPhwwy5xDwCxzA5078FTDzIGNklal9QmS9jQ89rMW9m5mTdCfcwKPAP8OPNq9EBF/031b0r3Ajobt34+Ijib1Z2Yt1p8rC70kaUJvj0kScA1weZP7MrOKlD0ncDGwJSLea1ibKOk3kl6UdHHJ329mLVb2LcJrgSca7ncBX42IbZK+AfxC0jkRsbPnD0qaB8wrWd/MShrwnoCkocBfA091r6XxY9vS7TeA94Gv9fbzHj5i1h7KHA78JbAuIjZ3L0g6vXsAqaRJFHMHNpRr0cxaqT9vET4BvAx8XdJmSTemh+bw5UMBgEuA1ektw/8GbomI/g4zNbMaDHTuABFxQy9rzwDPlG/LzKriTwyaZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJa57CYQ7dq1i6FDq3na27dvZ/v27ZXUAhgyZEhltXbv3l1Zra1bt7J///7KalX13Pbs2VNJncM57L8GSeMpLjc+GghgQUT8RNJIikuLTQA2AtdExCfpCsQ/Aa4GPgNuiIiVrWn/yD3//PMce+yxldTasWNHZSFwzDHHcMopp1RSKyJ48cUXK6kFxWtW1WiwTz75hB07dhx+w6NIfw4H9gPfj4gpwIXArZKmAPOB5RExGVie7gNcRXFZsckUFxJ9oOldm1nTHDYEIqKr+//kEbELWAuMBWYCC9NmC4FZ6fZM4NEorABGSBrT7MbNrDmO6MRgGkJyHvAKMDoiutJDH1EcLkAREB80/NjmtGZmbajfZ8gknURx/cA7ImJncehfiIiQFEdS2HMHzNpDv/YEJB1LEQCPRcSzaXlL925++r41rXcC4xt+fFxa+xLPHTBrD/255LiAh4C1EXFfw0NLgLnp9lxgccP69SpcCOxoOGwwszbTn8OBbwLXAW92jyAH7gJ+CDyd5hBsohhMCrCU4u3B9RRvEX6vmQ2bWXP1Z+7ArwH18fAVvWwfwK0l+zKzivhjw2aZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFgljmHgFnmHAJmmXMImGXOIWCWOYeAWeYcAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlTsXVwGpuQvo9sBv4Q929lDCKwd0/DP7nMNj7h9Y+hzMj4vSei20RAgCSXh/Mlx8f7P3D4H8Og71/qOc5+HDALHMOAbPMtVMILKi7gZIGe/8w+J/DYO8fangObXNOwMzq0U57AmZWg9pDQNKVkt6RtF7S/Lr76S9JGyW9KWmVpNfT2khJyyS9l76fVnefjSQ9LGmrpDUNa732nGZJ/jS9LqslnV9f53/qtbf+75HUmV6HVZKubnjsztT/O5K+U0/XX5A0XtKvJL0t6S1Jt6f1el+DiKjtCxgCvA9MAoYBvwWm1NnTEfS+ERjVY+1HwPx0ez7wr3X32aO/S4DzgTWH65linuQvKUbQXQi80qb93wP8Qy/bTkn/PQ0HJqb/zobU3P8Y4Px0+2Tg3dRnra9B3XsCFwDrI2JDRPwReBKYWXNPZcwEFqbbC4FZ9bVyqIh4Cfi4x3JfPc8EHo3CCmBE9yj6uvTRf19mAk9GxN6I+B3FgNwLWtZcP0REV0SsTLd3AWuBsdT8GtQdAmOBDxrub05rg0EAz0l6Q9K8tDY6vhjD/hEwup7WjkhfPQ+m1+a2tLv8cMMhWFv3L2kCcB7wCjW/BnWHwGB2UUScD1wF3CrpksYHo9ifG1RvvQzGnoEHgLOADqALuLfWbvpB0knAM8AdEbGz8bE6XoO6Q6ATGN9wf1xaa3sR0Zm+bwUWUexqbuneXUvft9bXYb/11fOgeG0iYktEHIiIg8CDfLHL35b9SzqWIgAei4hn03Ktr0HdIfAaMFnSREnDgDnAkpp7OixJJ0o6ufs28G1gDUXvc9Nmc4HF9XR4RPrqeQlwfTpDfSGwo2GXtW30OEaeTfE6QNH/HEnDJU0EJgOvVt1fI0kCHgLWRsR9DQ/V+xrUeba04QzouxRnb++uu59+9jyJ4szzb4G3uvsGvgIsB94DngdG1t1rj76foNhl3kdxfHljXz1TnJH+j/S6vAlMbdP+f576W53+0Yxp2P7u1P87wFVt0P9FFLv6q4FV6evqul8Df2LQLHN1Hw6YWc0cAmaZcwiYZc4hYJY5h4BZ5hwCZplzCJhlziFglrn/A2DgCkVHk+fjAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "examples = [4, 150, 1500, 1689]\n",
    "for ex in examples:\n",
    "    im = image.load_img(\n",
    "        Path.joinpath(img_path, f\"{ex}.png\").as_posix(),\n",
    "        target_size=(224,224)\n",
    "    )\n",
    "    plt.figure()\n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    y = custom_model.predict(np.array([image.img_to_array(im)]))\n",
    "    print(np.argmax(y))\n",
    "    print(\"---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto",
   "language": "python",
   "name": "proto"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
