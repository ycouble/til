<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Entraînement et intégration d’un classifieur de textes à une pipeline SpaCy | TIL</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Entraînement et intégration d’un classifieur de textes à une pipeline SpaCy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Customiser une pipelines SpaCy avec vos propres composants de NLP" />
<meta property="og:description" content="Customiser une pipelines SpaCy avec vos propres composants de NLP" />
<link rel="canonical" href="https://ycouble.github.io/til/fr/python/nlp/spacy/ml/mlops/2022/02/09/Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.html" />
<meta property="og:url" content="https://ycouble.github.io/til/fr/python/nlp/spacy/ml/mlops/2022/02/09/Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.html" />
<meta property="og:site_name" content="TIL" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-09T00:00:00-06:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Entraînement et intégration d’un classifieur de textes à une pipeline SpaCy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-02-09T00:00:00-06:00","datePublished":"2022-02-09T00:00:00-06:00","description":"Customiser une pipelines SpaCy avec vos propres composants de NLP","headline":"Entraînement et intégration d’un classifieur de textes à une pipeline SpaCy","mainEntityOfPage":{"@type":"WebPage","@id":"https://ycouble.github.io/til/fr/python/nlp/spacy/ml/mlops/2022/02/09/Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.html"},"url":"https://ycouble.github.io/til/fr/python/nlp/spacy/ml/mlops/2022/02/09/Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/til/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ycouble.github.io/til/feed.xml" title="TIL" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-09HCYPQMC0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-09HCYPQMC0');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/til/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" /><script src="https://hypothes.is/embed.js" async></script>

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/til/">TIL</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/til/about/">Yoann Couble</a><a class="page-link" href="/til/search/">Search</a><a class="page-link" href="/til/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Entraînement et intégration d&#39;un classifieur de textes à une pipeline SpaCy</h1><p class="page-description">Customiser une pipelines SpaCy avec vos propres composants de NLP</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-09T00:00:00-06:00" itemprop="datePublished">
        Feb 9, 2022
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/til/categories/#fr">fr</a>
        &nbsp;
      
        <a class="category-tags-link" href="/til/categories/#python">python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/til/categories/#nlp">nlp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/til/categories/#spacy">spacy</a>
        &nbsp;
      
        <a class="category-tags-link" href="/til/categories/#ml">ml</a>
        &nbsp;
      
        <a class="category-tags-link" href="/til/categories/#mlops">mlops</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-justify-center">
          <div class="px-2">

    <a href="https://github.com/ycouble/til/tree/master/_notebooks/2022-02-09-Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/til/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/ycouble/til/master?filepath=_notebooks%2F2022-02-09-Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/til/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/ycouble/til/blob/master/_notebooks/2022-02-09-Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/til/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-09-Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Introduction">Introduction<a class="anchor-link" href="#Introduction"> </a></h2><p>Spacy est une bibliothèque de Traitement Automatique du Langage Naturel (TANL ou NLP en anglais) et un framework pour industrialiser des applications de NLP et de Machine Learning.</p>
<p>Les ressources pour entraîner un modèle de machine learning sur du texte (classification, extraction d'entités, etc.) avec SpaCy ne manquent pas, mais très peu vont jusqu'au bout du chemin: l'intégration avec d'autres composants standards et pré-entraînés de SpaCy (ou d'autres fournisseurs), tels qu'un DependencyParser, tagger POS qui ne nécessitent pas de spécialisation ou de fine tuning.</p>
<p>C'est pour combler ce manque que <a href="https://github.com/ycouble/til/blob/master/_notebooks/2022-02-09-Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.ipynb">ce notebook</a> existe : <strong>vous guider dans le process de configuration d'un composant de classification de textes, de l'entraînement depuis un script python et jusqu'à son intégration dans une pipeline SpaCy pré-entraînée afin qu'elle soit réutilisable depuis le reste de vos applications.</strong>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Pre-requis">Pre-requis<a class="anchor-link" href="#Pre-requis"> </a></h3><p>Tout d'abord, installons les packages nécessaires pour ce tutoriel: spacy pour le NLP, pandas pour inspecter nos données, et sklearn qui va faciliter la séparation du jeu de données en splits.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">%</span><span class="k">pip</span> install -q &quot;spacy&gt;3.0.0&quot; pandas sklearn
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Note: you may need to restart the kernel to use updated packages.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nous devons également télécharger un modèle pré-entraîné de SpaCy : <a href="https://spacy.io/models/en#en_core_web_md">https://spacy.io/models/en#en_core_web_md</a>. La ligne de commande suivante doit être exécutée depuis le même environnement que votre kernel de notebook.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="o">!</span>python -m spacy download en_core_web_md
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Les-donn&#233;es-&amp;-la-t&#226;che-de-classification">Les donn&#233;es &amp; la t&#226;che de classification<a class="anchor-link" href="#Les-donn&#233;es-&amp;-la-t&#226;che-de-classification"> </a></h2><p>Nous travaillerons sur un dataset qui a été extrait à travers l'API de reddit. Le dataset a déjà été préparé et nettoyé pour qu'il puisse être facilement importé et converti en documents SpaCy.
<a href="https://github.com/ycouble/til/blob/master/_notebooks/spacy_textcat/reddit_data.csv">Vous pourrez le trouver ici</a>.</p>
<p>Le dataset est composé du corps de texte d'une selection de posts provenant de quelques subreddits liés à la data science.
L'objectif de notre tâche de machine learning sera de deviner à partir du corps de texte de quel subreddit le post provient.
Même si l'intérêt en soi est assez limité, c'est un bon point de départ pour démarrer et il présente l'avantage d'être déjà annoté.</p>
<p>Jettons un oeil à ce qu'il y a dans le dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_colwidth</span> <span class="o">=</span> <span class="kc">None</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_rows</span> <span class="o">=</span> <span class="mi">6</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;spacy_textcat/reddit_data.csv&quot;</span><span class="p">)</span>
<span class="n">data</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
      <th>tag</th>
      <th>subreddit</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>I’m looking for datasets or api source that quantifies fan base, or preferably, bettors’ sentiment regarding a team’s performance or direction. Does anyone know of an API that tracks this? For now I’m looking specifically for NBA, but am also interested in MLB, NFL, and NCAA f-ball and b-ball.</td>
      <td>API</td>
      <td>datasets</td>
      <td>s0vufk</td>
    </tr>
    <tr>
      <th>1</th>
      <td>I'm making an ESG stock analysis program in Java, and so far the only free ESG API I've come across is ESGEnterprise, but I'm having trouble retrieving the data. Has anyone had any success/have any recs for other ESG APIs out there.</td>
      <td>API</td>
      <td>datasets</td>
      <td>ruvj9n</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Hey everyone! I’m one of the creators of Sieve _URL_ and I’m excited to be sharing it!\nSieve _URL_ **is an API that helps you turn petabyte-scale video data into a high-quality dataset, automatically.**\nIt helps store, process, and semantically search your video data. Just think _NUMBER_ cameras recording footage at _NUMBER_ FPS, _NUMBER_/_NUMBER_. That would be _NUMBER_ million frames generated in a single day. The videos might be searchable by timestamp, but finding moments of interest is like searching for a needle in a haystack. Sieve tags useful attributes like people, motion, lighting, etc on every frame!\nWe built this visual demo (link here _URL_ a little while back which we’d love to get feedback on. It’s \~_NUMBER_ hours of security footage that our API processed in &lt;_NUMBER_ mins and has simple querying and export functionality enabled. We see applications in better understanding what data you have, figuring out which data to send to labeling, sampling datasets for training, and building multiple test sets for models by scenario.\nTo try it on your videos: _URL_ _URL_\nVisual dashboard walkthrough: Click on our site link!</td>
      <td>API</td>
      <td>datasets</td>
      <td>rup1uj</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>718</th>
      <td>I'm currently in the process of learning NLP. I am using catalyst on c#. \nI was able to run the sample programs and it was able to determine if the word is an noun, adjective, etc. But I can't find any sample for what I need.\nHere is a summary of what I would like to achieve. \nI would like to extract certain information on a sentence. Lets say i have the following texts:\n"Sally ate an orange this morning. "\nOr \n"Sally is hiding behind the cabinet and she is eating an orange. " \nHow do i use the nlp to extract what sally ate?</td>
      <td>NaN</td>
      <td>LanguageTechnology</td>
      <td>saas64</td>
    </tr>
    <tr>
      <th>719</th>
      <td>I’ve been trying to do some basic keyword extraction and finding it harder than expected.\nKeyBERT seems good but it requires a powerful GPU to be usably fast. That’s possible with AWS, but there’s a bit more set up.\nI just tried PyTextRank, and I was surprised at the quality of the output - I wouldn’t say it was perfect either. Maybe I should set a threshold, like choose the top _NUMBER_ ranked keywords? It’s fine if we exclude potential good keywords just to have a smaller list of good ones.\nHere’s a good article about _NUMBER_ different methods, which is helpful -\n_URL_\nIn theory, Spacy and BERT seem like the best options but they’re both a little complex. \nI think KW extraction really only needs a few layers or as Spacy would call them pipelines.\n_NUMBER_. accurate tokenization of words and punctuation symbols\n_NUMBER_. accurate recognition of multi-word expressions  - think of it as “chunking”\n_NUMBER_. Strong assessment of keyword “candidacy” for each MWE \nOf course, a good algorithm can often skip steps. Like BERT is so smart it doesn’t need anything but the input text.\nDoes anyone know of a simplest way to run a fast, effective keyword extraction?\nI’m talking _NUMBER_ keywords in one second on a fast CPU.\nThanks very much</td>
      <td>NaN</td>
      <td>LanguageTechnology</td>
      <td>s7qml8</td>
    </tr>
    <tr>
      <th>720</th>
      <td>This _URL_ position is currently open and I wanted to share with you!</td>
      <td>NaN</td>
      <td>LanguageTechnology</td>
      <td>s30ccv</td>
    </tr>
  </tbody>
</table>
<p>721 rows × 4 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cats</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">subreddit</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">cats</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;datasets&#39;, &#39;dataengineering&#39;, &#39;LanguageTechnology&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Le dataset est composé d'un peu plus de 700 posts et de leurs subreddits associé.
Créons maintenant les datasets d'entraînement et de validation en y incluant les annotations.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Cr&#233;ation-du-dataset-d'entra&#238;nement">Cr&#233;ation du dataset d'entra&#238;nement<a class="anchor-link" href="#Cr&#233;ation-du-dataset-d'entra&#238;nement"> </a></h2><p>Tout d'abord écrivons une fonction permettant de transformer le dataset dans le format binaire pour spacy, que l'on va stocker temporairement en local.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Set</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>
<span class="kn">from</span> <span class="nn">spacy.tokens</span> <span class="kn">import</span> <span class="n">DocBin</span>
<span class="kn">import</span> <span class="nn">spacy</span>

<span class="c1"># Load spaCy pretrained model that we downloaded before</span>
<span class="n">nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_md&quot;</span><span class="p">)</span>

<span class="c1"># Create a function to create a spacy dataset</span>
<span class="k">def</span> <span class="nf">make_docs</span><span class="p">(</span><span class="n">data</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]],</span> <span class="n">target_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">cats</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">str</span><span class="p">]):</span>
    <span class="n">docs</span> <span class="o">=</span> <span class="n">DocBin</span><span class="p">()</span>
    <span class="c1"># Use nlp.pipe to efficiently process a large number of text inputs, </span>
    <span class="c1"># the as_tuple arguments enables giving a list of tuples as input and </span>
    <span class="c1"># reuse it in the loop, here for the labels</span>
    <span class="k">for</span> <span class="n">doc</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">nlp</span><span class="o">.</span><span class="n">pipe</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">as_tuples</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># Encode the labels (assign 1 the subreddit)</span>
        <span class="k">for</span> <span class="n">cat</span> <span class="ow">in</span> <span class="n">cats</span><span class="p">:</span>
            <span class="n">doc</span><span class="o">.</span><span class="n">cats</span><span class="p">[</span><span class="n">cat</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">cat</span> <span class="o">==</span> <span class="n">label</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">docs</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">doc</span><span class="p">)</span>
    <span class="n">docs</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="n">target_file</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">docs</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Séparons jeux d'entraînement et de validation.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s2">&quot;subreddit&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">make_docs</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)),</span> <span class="s2">&quot;train.spacy&quot;</span><span class="p">,</span> <span class="n">cats</span><span class="o">=</span><span class="n">cats</span><span class="p">)</span>
<span class="n">make_docs</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">)),</span> <span class="s2">&quot;valid.spacy&quot;</span><span class="p">,</span> <span class="n">cats</span><span class="o">=</span><span class="n">cats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;spacy.tokens._serialize.DocBin at 0x12b189100&gt;</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Creation-et-configuration-du-composant-de-classification-de-textes">Creation et configuration du composant de classification de textes<a class="anchor-link" href="#Creation-et-configuration-du-composant-de-classification-de-textes"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Le workflow recommandé avec SpaCy utilise des fichiers de configuration. Ils permettent de configurer chaque composant de la pipeline, de choisir quels composant entrâiner etc.</p>
<p>Nous utiliserons <a href="https://github.com/ycouble/til/blob/master/_notebooks/spacy_textcat/config.cfg">ce fichier de configuration</a>, qui utilises le classifieur de textes par défaut de SpaCy.
La configuration peut être re-générée en suivant ce guide : <a href="https://spacy.io/usage/training#quickstart">https://spacy.io/usage/training#quickstart</a> et nous l'avons customisé pour qu'il utilise ce model proposé par SpaCy également : <a href="https://spacy.io/api/architectures#TextCatBOW">https://spacy.io/api/architectures#TextCatBOW</a>.</p>
<p>Il y a deux parties qu'il est important de noter dans ce fichier :</p>
<ol>
<li>La définition de la pipeline (sous le header <code>nlp</code>): La pipeline ne contient que le composant textcat (de classification) puisque c'est celui pour lequel nous avons des données annotées et le seul que nous allons entraîner aujourd'hui. Un autre détail qui a son importance est le tokenizer qui, comme on peut le voir est spécifié à cet endroit, et est ici laissé à la valeur par défaut proposée par SpaCy. C'est le seul pré-requis pour notre composant <code>textcat</code>.</li>
</ol>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="kc">nl</span><span class="err">p</span><span class="p">]</span>
<span class="err">la</span><span class="kc">n</span><span class="err">g</span> <span class="err">=</span> <span class="s2">&quot;en&quot;</span>
<span class="err">pipeli</span><span class="kc">ne</span> <span class="err">=</span> <span class="p">[</span><span class="s2">&quot;textcat&quot;</span><span class="p">]</span>
<span class="err">ba</span><span class="kc">t</span><span class="err">ch_size</span> <span class="err">=</span> <span class="mi">1000</span>
<span class="err">disabled</span> <span class="err">=</span> <span class="p">[]</span>
<span class="err">be</span><span class="kc">f</span><span class="err">ore_crea</span><span class="kc">t</span><span class="err">io</span><span class="kc">n</span> <span class="err">=</span> <span class="kc">null</span>
<span class="err">a</span><span class="kc">fter</span><span class="err">_crea</span><span class="kc">t</span><span class="err">io</span><span class="kc">n</span> <span class="err">=</span> <span class="kc">null</span>
<span class="err">a</span><span class="kc">fter</span><span class="err">_pipeli</span><span class="kc">ne</span><span class="err">_crea</span><span class="kc">t</span><span class="err">io</span><span class="kc">n</span> <span class="err">=</span> <span class="kc">null</span>
<span class="kc">t</span><span class="err">oke</span><span class="kc">n</span><span class="err">izer</span> <span class="err">=</span> <span class="p">{</span><span class="nt">&quot;@tokenizers&quot;</span><span class="p">:</span><span class="s2">&quot;spacy.Tokenizer.v1&quot;</span><span class="p">}</span>
</pre></div>
<ol>
<li>La spécification du modèle : Notons le paramètre  <code>exclusive_classes</code> qui a été mis à <code>true</code> puisque nos posts ne viennent que d'un seul subreddit. Notons aussi qu'il a fallu rajouter le prefix <code>components.textcat</code> dans les headers à la configuration donnée dans la documentation.</li>
</ol>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="err">compo</span><span class="kc">nents</span><span class="err">.</span><span class="kc">te</span><span class="err">x</span><span class="kc">t</span><span class="err">ca</span><span class="kc">t</span><span class="p">]</span>
<span class="kc">fa</span><span class="err">c</span><span class="kc">t</span><span class="err">ory</span> <span class="err">=</span> <span class="s2">&quot;textcat&quot;</span>
<span class="err">scorer</span> <span class="err">=</span> <span class="p">{</span><span class="nt">&quot;@scorers&quot;</span><span class="p">:</span><span class="s2">&quot;spacy.textcat_scorer.v1&quot;</span><span class="p">}</span>
<span class="kc">t</span><span class="err">hreshold</span> <span class="err">=</span> <span class="mf">0.5</span>

<span class="p">[</span><span class="err">compo</span><span class="kc">nents</span><span class="err">.</span><span class="kc">te</span><span class="err">x</span><span class="kc">t</span><span class="err">ca</span><span class="kc">t</span><span class="err">.model</span><span class="p">]</span>
<span class="err">@archi</span><span class="kc">te</span><span class="err">c</span><span class="kc">tures</span> <span class="err">=</span> <span class="s2">&quot;spacy.TextCatBOW.v2&quot;</span>
<span class="err">exclusive_classes</span> <span class="err">=</span> <span class="kc">true</span>
<span class="kc">n</span><span class="err">gram_size</span> <span class="err">=</span> <span class="mi">1</span>
<span class="kc">n</span><span class="err">o_ou</span><span class="kc">t</span><span class="err">pu</span><span class="kc">t</span><span class="err">_layer</span> <span class="err">=</span> <span class="kc">false</span>
<span class="kc">n</span><span class="err">O</span> <span class="err">=</span> <span class="kc">null</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<details>
  <summary>Plus de détails sur les pipelines SpaCy</summary>
Une pipeline SpaCy est une architecture logicielle hautement modulaire et configurable spécialisée pour le traitement automatique de textes.
Comme on peut le voir sur l'illustration plus bas, la pipeline contient une étape obligatoire qui est la tokenisation du document, brique de base utilisée par l'ensemble les algorithmes d'analyse de documents.
Ensuite viennent une succession de composants (ou pipes) qui sont éxécutés dans l'ordre spécifié, mais qui ne dépendent pas nécessairement les uns des autres.
Cela sera dans le code du composant que ces dépendences vont se définir, par exemple en accédant à des attributs définis dans l'objet document de SpaCy.
<figure>
  
    <img class="docimage" src="/til/images/copied_from_nb/spacy_textcat/spacy_pipeline.png" alt="" />
    
    
</figure>

</details>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Entra&#238;nement-du-composant-de-classification-de-textes">Entra&#238;nement du composant de classification de textes<a class="anchor-link" href="#Entra&#238;nement-du-composant-de-classification-de-textes"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Contrairement à ce qui peut être trouvé dans la plupart des tutoriels en ligne ou dans la documentation de SpaCy où l'entraînement est démarré depuis la CLI, nous allons essayer de lancer l'entraînement du composant directement depuis un script python.
Cela a l'avantage de pouvoir faire cette étape de manière programmatique, par exemple depuis une pipeline de donnée (avec airflow, dagster, ou équivalent).</p>
<p>Toutefois, nous utiliserons la fonction <code>train</code> pré-définie dans <code>spacy.cli.train</code> de telles sorte à bénéficier des fonctionalités de logging, adaptations et autres vérifications qui sont utilisée dans la CLI.
Notons que l'on peut tout à fait, et très facilement partir directement du module <code>spacy.training</code> et de gérer le logging / interaction avec le système de fichier par nous même, ce qui serait recommandé dans du code de production.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">spacy.cli.train</span> <span class="kn">import</span> <span class="n">train</span> <span class="k">as</span> <span class="n">spacy_train</span>

<span class="n">config_path</span> <span class="o">=</span> <span class="s2">&quot;spacy_textcat/config.cfg&quot;</span>
<span class="n">output_model_path</span> <span class="o">=</span> <span class="s2">&quot;output/spacy_textcat&quot;</span>
<span class="n">spacy_train</span><span class="p">(</span>
    <span class="n">config_path</span><span class="p">,</span>
    <span class="n">output_path</span><span class="o">=</span><span class="n">output_model_path</span><span class="p">,</span>
    <span class="n">overrides</span><span class="o">=</span><span class="p">{</span>
        <span class="s2">&quot;paths.train&quot;</span><span class="p">:</span> <span class="s2">&quot;train.spacy&quot;</span><span class="p">,</span>
        <span class="s2">&quot;paths.dev&quot;</span><span class="p">:</span> <span class="s2">&quot;valid.spacy&quot;</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre><span class="ansi-blue-fg">ℹ Saving to output directory: output/spacy_textcat</span>
<span class="ansi-blue-fg">ℹ Using CPU</span>
<span class="ansi-bold">
=========================== Initializing pipeline ===========================</span>
<span class="ansi-green-fg">✔ Initialized pipeline</span>
<span class="ansi-bold">
============================= Training pipeline =============================</span>
<span class="ansi-blue-fg">ℹ Pipeline: [&#39;textcat&#39;]</span>
<span class="ansi-blue-fg">ℹ Initial learn rate: 0.001</span>
E    #       LOSS TEXTCAT  CATS_SCORE  SCORE 
---  ------  ------------  ----------  ------
  0       0          0.67        3.31    0.03
  0     200         97.52       46.14    0.46
  0     400         59.67       61.38    0.61
  1     600         19.23       73.74    0.74
  1     800         11.17       75.77    0.76
  2    1000          2.12       74.20    0.74
  3    1200          1.19       75.33    0.75
  4    1400          0.71       76.68    0.77
  4    1600          0.35       75.91    0.76
  6    1800          0.28       77.79    0.78
  7    2000          0.21       77.91    0.78
  9    2200          0.18       77.49    0.77
 11    2400          0.06       79.36    0.79
 13    2600          0.05       77.81    0.78
 16    2800          0.03       77.81    0.78
 19    3000          0.03       77.98    0.78
 21    3200          0.03       77.05    0.77
 24    3400          0.06       77.95    0.78
 27    3600          0.02       76.41    0.76
 30    3800          0.03       75.48    0.75
 32    4000          0.02       77.60    0.78
<span class="ansi-green-fg">✔ Saved pipeline to output directory</span>
output/spacy_textcat/model-last
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Nous avons maintenant un modèle de classification entraîné !
Spacy stocke le modèle dans des dossiers, et en sauve deux versions, le dernier état du modèle pour permettre de reprendre depuis ce checkpoint s'il on veut affiner le modèle, et le meilleur état du modèle observé pendant l'entraînement.
Dans le fichier <code>meta.json</code> dans le dossier du modèle, on peut voir les scores interne qui ont été calculés pendant la validation, et l'on peut voir ici des scores de ~.8 en Macro F score et un AUC à .93.</p>
<p>Le modèle ainsi entraîné et stocké peut ensuite être chargé via spacy de cette manière :</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">spacy</span>

<span class="n">trained_nlp</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;output/spacy_textcat/model-best&quot;</span><span class="p">)</span>

<span class="c1"># Let&#39;s try it on an example text</span>
<span class="n">text</span> <span class="o">=</span> <span class="s2">&quot;Hello</span><span class="se">\n</span><span class="s2"> I&#39;m looking for data about birds in New Zealand.</span><span class="se">\n</span><span class="s2">The dataset would contain the birds species, colors, estimated population etc.&quot;</span>
<span class="c1"># Perform the trained pipeline on this text</span>
<span class="n">doc</span> <span class="o">=</span> <span class="n">trained_nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="c1"># We can display the predicted categories</span>
<span class="n">doc</span><span class="o">.</span><span class="n">cats</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>{&#39;datasets&#39;: 0.8466417193412781,
 &#39;dataengineering&#39;: 0.07126601785421371,
 &#39;LanguageTechnology&#39;: 0.08209223300218582}</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>On voit que le document une fois traité par la nouvelle pipeline dispose d'un attributs <code>.cats</code> et que dans ce cas la catégorie <code>datasets</code> est prédite avec 84% de confiance.</p>
<p>Cependant, le reste de la pipeline est vide : pas d'information syntaxique, de dépendance ou d'entités.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;entities&quot;</span><span class="p">,</span> <span class="n">doc</span><span class="o">.</span><span class="n">ents</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sentences&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">sents</span><span class="p">))</span>
<span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sentences&quot;</span><span class="p">,</span> <span class="s2">&quot;error:&quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>entities ()
sentences error: [E030] Sentence boundaries unset. You can add the &#39;sentencizer&#39; component to the pipeline with: `nlp.add_pipe(&#39;sentencizer&#39;)`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Ces informations sont en revanche disponible et dans la pipeline pré-entraînée que nous avions utilisée au début (Mais évidemment, pas les catégories).</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">doc_from_pretrained</span> <span class="o">=</span> <span class="n">nlp</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;entities&quot;</span><span class="p">,</span> <span class="n">doc_from_pretrained</span><span class="o">.</span><span class="n">ents</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sentences&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">doc_from_pretrained</span><span class="o">.</span><span class="n">sents</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span> <span class="n">doc_from_pretrained</span><span class="o">.</span><span class="n">cats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>entities (New Zealand,)
sentences [Hello
 I&#39;m looking for data about birds in New Zealand., 
, The dataset would contain the birds species, colors, estimated population etc.]
classification {}
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>La question est donc, <strong>comment combiner les deux pipelines nativement</strong> sans avoir à charger deux modèles séparément et écrire beaucoup de code pour recoller les morceaux ?</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Int&#233;gration-du-nouveaux-composant-dans-la-pipeline-existante">Int&#233;gration du nouveaux composant dans la pipeline existante<a class="anchor-link" href="#Int&#233;gration-du-nouveaux-composant-dans-la-pipeline-existante"> </a></h2><p>Il y a en fait plusieurs manière de le faire :</p>
<ol>
<li>Créer un pipe et charger le modèle à partir du système de fichiers, mais cela aurait demandé d'utiliser un processus d'entraînement différent de celui que nous avons utilisé ici.<div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">)</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">from_disk</span><span class="p">(</span><span class="s2">&quot;path/to/model/files&quot;</span><span class="p">)</span> <span class="c1"># Note, requires a different folder structure that what we&#39;ve generated</span>
</pre></div>
</li>
<li>Charger la pipeline, sauver le modèle du composant dans un fichier ou sous forme binaire, et le charger à nouveau dans un second temps depuis le disque / le binaire dans un nouveau pipe ajouté à la pipeline pré-entraînée.<div class="highlight"><pre><span></span><span class="n">trained_nlp</span><span class="o">.</span><span class="n">get_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_disk</span><span class="p">(</span><span class="s2">&quot;tmp&quot;</span><span class="p">)</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">from_disk</span><span class="p">(</span><span class="s2">&quot;tmp&quot;</span><span class="p">)</span>
<span class="c1"># OR</span>
<span class="n">nlp</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">from_bytes</span><span class="p">(</span>
 <span class="n">trained_nlp</span><span class="o">.</span><span class="n">get_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to_bytes</span><span class="p">()</span>
<span class="p">)</span>
</pre></div>
</li>
<li>Créer le pipe depuis une pipeline source.</li>
</ol>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">nlp_merged</span> <span class="o">=</span> <span class="n">spacy</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;en_core_web_md&quot;</span><span class="p">)</span>
<span class="n">nlp_merged</span><span class="o">.</span><span class="n">add_pipe</span><span class="p">(</span><span class="s2">&quot;textcat&quot;</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">trained_nlp</span><span class="p">)</span>
<span class="n">doc_from_merged</span> <span class="o">=</span> <span class="n">nlp_merged</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;entities&quot;</span><span class="p">,</span> <span class="n">doc_from_merged</span><span class="o">.</span><span class="n">ents</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sentences&quot;</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">doc_from_merged</span><span class="o">.</span><span class="n">sents</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span> <span class="n">doc_from_merged</span><span class="o">.</span><span class="n">cats</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>entities (New Zealand,)
sentences [Hello
 I&#39;m looking for data about birds in New Zealand., 
, The dataset would contain the birds species, colors, estimated population etc.]
classification {&#39;datasets&#39;: 0.8466417193412781, &#39;dataengineering&#39;: 0.07126601785421371, &#39;LanguageTechnology&#39;: 0.08209223300218582}
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/Users/yco/.pyenv/versions/myreddit/lib/python3.8/site-packages/spacy/language.py:707: UserWarning: [W113] Sourced component &#39;textcat&#39; may not work as expected: source vectors are not identical to current pipeline vectors.
  warnings.warn(Warnings.W113.format(name=source_name))
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>À partir de là, il est possible de sauver la pipeline sur le disque et de la réutiliser à volonté, ou encore de l'enrichir avec d'autres composants personalisés (pourquoi pas un second classifier, ou encore un modèle de NER complémentaire de celui présent dans la pipeline) avec l'ensemble des fonctionalités.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion"> </a></h2><p>Dans ce tutoriel, nous avons vu comment entraîner et intégrer un composant de classification de textes à une pipeline pré-existante, d'une manière complètement programmatique.
La grande valeur ajoutée de cette procédure est qu'elle peut être complètement automatisée et permettre d'entraîner / assembler un grand nombre de composants de manière modulaire et automatique (par exemple en CI/CD)</p>
<p>J'espère que le post vous auta été utile et n'hésitez pas à me contacter si vous voulez plus de détails dans les commentaires !</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="ycouble/til"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/til/fr/python/nlp/spacy/ml/mlops/2022/02/09/Entrainement-et-integration-d-un-classifieur-de-textes-a-une-pipeline-spacy.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/til/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/til/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/til/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Today I Learnt</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://gitlab.com/ycouble" target="_blank" title="ycouble"><svg class="svg-icon grey"><use xlink:href="/til/assets/minima-social-icons.svg#gitlab"></use></svg></a></li><li><a rel="me" href="https://github.com/ycouble" target="_blank" title="ycouble"><svg class="svg-icon grey"><use xlink:href="/til/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/yoann-couble" target="_blank" title="yoann-couble"><svg class="svg-icon grey"><use xlink:href="/til/assets/minima-social-icons.svg#linkedin"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
