{
  
    
        "post0": {
            "title": "La Famille BERT et les Transformers",
            "content": "%pip install --upgrade -q pandas torch transformers &quot;spacy&gt;=3.2.0&quot; spacy-transformers . huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks... To disable this warning, you can either: - Avoid using `tokenizers` before the fork if possible - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false) WARNING: You are using pip version 21.1.1; however, version 21.3.1 is available. You should consider upgrading via the &#39;/Users/yco/.pyenv/versions/proto-38dev/bin/python -m pip install --upgrade pip&#39; command. Note: you may need to restart the kernel to use updated packages. . Ressources . R&#233;f&#233;rences . Attention is all you need (2016, Transformer paper): https://arxiv.org/abs/1706.03762 | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (2018): https://arxiv.org/abs/1810.04805 | . Illustrated transformer: http://jalammar.github.io/illustrated-transformer/ | BERT model doc on hugging face: https://huggingface.co/transformers/model_doc/bert.html#bertmodel | https://spacy.io/usage/embeddings-transformers | . Exemples . Exemple de configuration sur le hub de huggingface: https://huggingface.co/dslim/bert-base-NER/blob/main/config.json | Transformers pour le NER FR https://huggingface.co/models?language=fr&amp;pipeline_tag=token-classification&amp;sort=downloads&amp;search=ner | Facebook Language AI Research NER: https://huggingface.co/flair/ner-french (Org, Per, Loc, Names) | https://towardsdatascience.com/easy-fine-tuning-of-transformers-for-named-entity-recognition-d72f2b5340e3 | https://skimai.com/how-to-fine-tune-bert-for-named-entity-recognition-ner/ | Use huggingface transformers within spacy: https://reposhub.com/python/deep-learning/explosion-spacy-transformers.html | . Cours et ressources formatrices . https://www.coursera.org/learn/attention-models-in-nlp/home/welcome | https://huggingface.co/course/chapter1 | https://course.spacy.io/en/chapter4 | https://www.youtube.com/playlist?list=PL75e0qA87dlG-za8eLI6t0_Pbxafk-cxb | . Why Transformers / BERT ? . Les Transformers s&#39;appuient sur le mécanisme d&#39;attention, qui a prouvé son efficacité | Les Transformers sont une architecture de deep learning générique, applicable à toutes les tâches de NLP | Les tâches de NLP (classification, NER, traduction, QA, ...) se ressemblent beaucoup, et une grande partie de l&#39;effort est commun: comprendre la structure d&#39;un langage, les relations entre les mots etc. Il y a un intérêt important à avoir un moyen de mutualiser cette approche pour transférer la connaissance | Le word / sentence embeddings sont un premier pas dans ce sens, mais pas sur les relations entre les mots ni sur le sens des phrases | . | . What are they ? . Un transformer est une architecture de deep learning qui utilise le mécanisme d&#39;attention: l&#39;importance de chaque mot de la phrase par rapport à chaque autre mot est prise en compte | . . L&#39;architecture Transformer est composée d&#39;un encoder et d&#39;un decoder, tous deux basés sur le mécanisme d&#39;attention. Dans le décodeur l&#39;attention est dite causale (ou masquée), c&#39;est à dire qu&#39;on ne regarde que les mots passés. | . . BERT est initialement une approche de pre-training pour capturer les relations dans un langage, l&#39;entraînement se fait sur une tâche auto-supervisée (self-supervised) ce qui permet de l&#39;entraîner sur de grande quantité de données. Le fine tuning se fait ensuite en utilisant le transfer learning | . . How to use Transformers . BERT et les autres transformers sont conçus pour être réutilisable en grande partie pour différentes tâche, il ne reste donc qu&#39;à réadapter les entrées et sorties à la tâche visée . &#129303; Transformers . Hugging Face a construit toute une API pour faciliter l&#39;utilisation des transformers. La librairie propose des pipelines pré-définies et une bibliothèque de modèles et de datasets prêtes à l&#39;emplois. . La configuration d&#39;un modèle se fait très facilement (sans code) à l&#39;aide d&#39;un fichier de configuration: https://huggingface.co/dslim/bert-base-NER/blob/main/config.json . { &quot;_num_labels&quot;: 9, &quot;architectures&quot;: [ &quot;BertForTokenClassification&quot; ], &quot;attention_probs_dropout_prob&quot;: 0.1, &quot;hidden_act&quot;: &quot;gelu&quot;, &quot;hidden_dropout_prob&quot;: 0.1, &quot;hidden_size&quot;: 768, &quot;initializer_range&quot;: 0.02, &quot;intermediate_size&quot;: 3072, &quot;layer_norm_eps&quot;: 1e-12, &quot;max_position_embeddings&quot;: 512, &quot;model_type&quot;: &quot;bert&quot;, &quot;num_attention_heads&quot;: 12, &quot;num_hidden_layers&quot;: 12, &quot;output_past&quot;: true, &quot;pad_token_id&quot;: 0, &quot;type_vocab_size&quot;: 2, &quot;vocab_size&quot;: 28996, # Labels &quot;id2label&quot;: { &quot;0&quot;: &quot;O&quot;, &quot;1&quot;: &quot;B-MISC&quot;, &quot;2&quot;: &quot;I-MISC&quot;, &quot;3&quot;: &quot;B-PER&quot;, &quot;4&quot;: &quot;I-PER&quot;, &quot;5&quot;: &quot;B-ORG&quot;, &quot;6&quot;: &quot;I-ORG&quot;, &quot;7&quot;: &quot;B-LOC&quot;, &quot;8&quot;: &quot;I-LOC&quot; }, &quot;label2id&quot;: { &quot;B-LOC&quot;: 7, &quot;B-MISC&quot;: 1, &quot;B-ORG&quot;: 5, &quot;B-PER&quot;: 3, &quot;I-LOC&quot;: 8, &quot;I-MISC&quot;: 2, &quot;I-ORG&quot;: 6, &quot;I-PER&quot;: 4, &quot;O&quot;: 0 } } . Ici l&#39;architecture choisie est BertForTokenClassification ce qui correspond à une tâche de NER (affecter à chaque token un label). Et on retrouve aussi les différents hyper-paramètres des transformers (nombre de têtes d&#39;attention, paramètres d&#39;attention, ...). Pour pouvoir réutiliser les poids d&#39;entraînement d&#39;un modèle pré-entraîné, il ne faut faire attention à ne changer que ce qui ne casse pas la compatibilité avec le modèle pré-entraîné. . Note: Les labels sont définis avec le mode d&#39;anotation &quot;IOB&quot; (I: Inside entity, O: Outside entity, B: Beginning of entity) ex: Je suis Yoann Couble serait annoté &quot;O O B-PER I-PER&quot;. . Solution 1: use a pre-defined / pre-trained model . from transformers import AutoTokenizer, AutoModelForTokenClassification from transformers import pipeline model_name = &quot;dslim/bert-base-NER&quot; . Get model and associated tokenizer from model hub . tokenizer = AutoTokenizer.from_pretrained(model_name) model = AutoModelForTokenClassification.from_pretrained(model_name) . Define pipeline . nlp = pipeline(&quot;ner&quot;, model=model, tokenizer=tokenizer) . Use on example . example = &quot;My name is Wolfgang and I live in Berlin&quot; ner_results = nlp(example) print(ner_results) . [{&#39;word&#39;: &#39;Wolfgang&#39;, &#39;score&#39;: 0.9990139603614807, &#39;entity&#39;: &#39;B-PER&#39;, &#39;index&#39;: 4, &#39;start&#39;: 11, &#39;end&#39;: 19}, {&#39;word&#39;: &#39;Berlin&#39;, &#39;score&#39;: 0.9996449947357178, &#39;entity&#39;: &#39;B-LOC&#39;, &#39;index&#39;: 9, &#39;start&#39;: 34, &#39;end&#39;: 40}] . Solution 2: use the raw BERT model and customize its heads . Start from a raw BERT model without any head, but where the weights can be re-used. Create a child class and define the __init__ and forward methods, see example from BertForTokenClassification. . Example from BertForTokenClassification . class BertForTokenClassification(BertPreTrainedModel): def __init__(self, config): super().__init__(config) self.num_labels = config.num_labels self.bert = BertModel(config, add_pooling_layer=False) classifier_dropout = ( config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob ) self.dropout = nn.Dropout(classifier_dropout) self.classifier = nn.Linear(config.hidden_size, config.num_labels) self.init_weights() def forward( self, input_ids=None, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None, inputs_embeds=None, labels=None, output_attentions=None, output_hidden_states=None, return_dict=None, ): ... # See doc linked above . Within Spacy . Spacy est complètement intégré dans huggingface, il est donc possible de les réutiliser à l&#39;intérieur des pipelines spacy. . Spacy fourni également des modèles pré-entraînés et bien intégrés à Spacy. Ce sont les modèles finissant en _trf comme celui-ci basé sur camembert-base . Download the model within your virtual environment / kernel (in my case, it&#39;s a pyenv environment) . pyenv activate 3.8.6 python -m spacy download en_core_web_trf . import spacy from spacy import displacy nlp = spacy.load(&quot;en_core_web_trf&quot;) doc = nlp(&quot;My name is Wolfgang and I live in Berlin&quot;) displacy.render(doc, &quot;ent&quot;) . My name is Wolfgang PERSON and I live in Berlin GPE",
            "url": "https://ycouble.github.io/til/fr/nlp/2021/11/23/bert.html",
            "relUrl": "/fr/nlp/2021/11/23/bert.html",
            "date": " • Nov 23, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Transfer Learning",
            "content": "from keras.models import Sequential import cv2 get_ipython().magic(&#39;matplotlib inline&#39;) import matplotlib.pyplot as plt import numpy as np import keras from keras.layers import Dense import pandas as pd from keras.applications.vgg16 import VGG16 from keras.preprocessing import image from keras.applications.vgg16 import preprocess_input import numpy as np from keras.applications.vgg16 import decode_predictions from pathlib import Path mnist_path = Path(&quot;mnist&quot;) img_path = Path(&quot;mnist/images/&quot;) . Generate Dataset from scikit learn dataset . from sklearn import datasets digits = datasets.load_digits() for i, im in enumerate(digits[&#39;images&#39;]): cv2.imwrite(Path.joinpath(img_path, f&quot;{i}.png&quot;).as_posix(),im*16) (pd.DataFrame({&quot;labels&quot;: digits[&quot;target&quot;]}) .to_csv(Path.joinpath(img_path, &quot;labels.csv&quot;).as_posix()) ) nb_img = len(list(img_path.glob(&#39;*.png&#39;))) limit = int(nb_img*0.75) train_range = range(limit) test_range = range(limit, nb_img) print(nb_img, limit, train_range, test_range) . 1797 1347 range(0, 1347) range(1347, 1797) . train_img=[] for i in train_range: temp_img=image.load_img( Path.joinpath(img_path, f&quot;{i}.png&quot;).as_posix(), target_size=(224,224) ) temp_img=image.img_to_array(temp_img) train_img.append(temp_img) #converting train images to array and applying mean subtraction processing train_img=np.array(train_img) train_img=preprocess_input(train_img) # applying the same procedure with the test dataset test_img=[] for i in test_range: temp_img=image.load_img( Path.joinpath(img_path, f&quot;{i}.png&quot;).as_posix(), target_size=(224,224) ) temp_img=image.img_to_array(temp_img) test_img.append(temp_img) test_img=np.array(test_img) test_img=preprocess_input(test_img) . (224, 224, 3) . transferred_model = VGG16(weights=&#39;imagenet&#39;, include_top=False) transferred_model.summary() . Model: &#34;vgg16&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_8 (InputLayer) [(None, None, None, 3)] 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, None, None, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, None, None, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, None, None, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, None, None, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, None, None, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, None, None, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, None, None, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, None, None, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, None, None, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, None, None, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, None, None, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, None, None, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, None, None, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, None, None, 512) 0 ================================================================= Total params: 14,714,688 Trainable params: 14,714,688 Non-trainable params: 0 _________________________________________________________________ . re_extract_features = False if re_extract_features: # Extracting features from the train dataset using the VGG16 pre-trained model features_train=transferred_model.predict(train_img) # Extracting features from the train dataset using the VGG16 pre-trained model features_test=transferred_model.predict(test_img) else: import h5py with h5py.File(&quot;mnist/mnist_features.hdf5&quot;, &quot;r&quot;) as f: features_train = np.array(f[&quot;features/train&quot;]) features_test = np.array(f[&quot;features/test&quot;]) print(features_train.shape, features_test.shape) . (1347, 7, 7, 512) (450, 7, 7, 512) . Store the model and the features . features_train.shape, features_test.shape . ((1347, 7, 7, 512), (450, 7, 7, 512)) . import h5py . with h5py.File(&quot;mnist/mnist_features.hdf5&quot;, &quot;w&quot;) as f: dset_train = f.create_dataset(&quot;features/train&quot;, data=features_train) dset_test = f.create_dataset(&quot;features/test&quot;, data=features_test) . Note: Ajouter une phase de mise en évidence des features #explainability . Adapt features to new MLP . labels = pd.read_csv(Path.joinpath(img_path, &quot;labels.csv&quot;).as_posix(), index_col=0) labels . labels . 0 0 | . 1 1 | . 2 2 | . 3 3 | . 4 4 | . ... ... | . 1792 9 | . 1793 0 | . 1794 8 | . 1795 9 | . 1796 8 | . 1797 rows × 1 columns . train_x=features_train.reshape(features_train.shape[0], 25088) # converting target variable to array train_y=labels[&quot;labels&quot;].values[train_range] # performing one-hot encoding for the target variable train_y=pd.get_dummies(train_y) train_y=np.array(train_y) # creating training and validation set print(&quot;Training set&quot;, train_x.shape, train_y.shape) # flattening the layers to conform to MLP input (N, 7, 7, 512) --&gt; (N, 25088) test_x=features_test.reshape(features_test.shape[0], 25088) # converting target variable to array test_y=labels[&quot;labels&quot;].values[test_range] # performing one-hot encoding for the target variable test_y=pd.get_dummies(test_y) test_y=np.array(test_y) # creating testing and validation set print(&quot;Testing set&quot;, test_x.shape, test_y.shape) . Training set (1347, 25088) (1347, 10) Testing set (450, 25088) (450, 10) . Create the MLP model . from keras.layers import Dense, Activation model=Sequential() model.add(Dense(1000, input_dim=25088, activation=&#39;relu&#39;,kernel_initializer=&#39;uniform&#39;)) keras.layers.core.Dropout(0.3, noise_shape=None, seed=None) model.add(Dense(500,input_dim=1000,activation=&#39;sigmoid&#39;)) keras.layers.core.Dropout(0.4, noise_shape=None, seed=None) model.add(Dense(150,input_dim=500,activation=&#39;sigmoid&#39;)) keras.layers.core.Dropout(0.2, noise_shape=None, seed=None) model.add(Dense(units=10)) model.add(Activation(&#39;softmax&#39;)) model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&quot;adam&quot;, metrics=[&#39;accuracy&#39;]) model.summary() . Train the new model . model.fit( train_x, train_y, epochs=20, batch_size=128, validation_data=(test_x,test_y), ) . Epoch 1/20 11/11 [==============================] - 2s 117ms/step - loss: 2.3253 - accuracy: 0.1903 - val_loss: 1.8503 - val_accuracy: 0.7089 Epoch 2/20 11/11 [==============================] - 1s 101ms/step - loss: 1.7412 - accuracy: 0.7974 - val_loss: 1.3985 - val_accuracy: 0.8378 Epoch 3/20 11/11 [==============================] - 1s 103ms/step - loss: 1.2646 - accuracy: 0.9024 - val_loss: 0.9943 - val_accuracy: 0.9289 Epoch 4/20 11/11 [==============================] - 1s 103ms/step - loss: 0.8349 - accuracy: 0.9636 - val_loss: 0.6862 - val_accuracy: 0.9378 Epoch 5/20 11/11 [==============================] - 1s 105ms/step - loss: 0.5149 - accuracy: 0.9812 - val_loss: 0.4834 - val_accuracy: 0.9422 Epoch 6/20 11/11 [==============================] - 1s 104ms/step - loss: 0.3083 - accuracy: 0.9904 - val_loss: 0.3589 - val_accuracy: 0.9356 Epoch 7/20 11/11 [==============================] - 1s 101ms/step - loss: 0.1978 - accuracy: 0.9961 - val_loss: 0.2829 - val_accuracy: 0.9489 Epoch 8/20 11/11 [==============================] - 1s 100ms/step - loss: 0.1226 - accuracy: 0.9994 - val_loss: 0.2266 - val_accuracy: 0.9533 Epoch 9/20 11/11 [==============================] - 1s 101ms/step - loss: 0.0802 - accuracy: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9556 Epoch 10/20 11/11 [==============================] - 1s 102ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1785 - val_accuracy: 0.9578 Epoch 11/20 11/11 [==============================] - 1s 103ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 0.9578 Epoch 12/20 11/11 [==============================] - 1s 105ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 0.1577 - val_accuracy: 0.9622 Epoch 13/20 11/11 [==============================] - 1s 103ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 0.1556 - val_accuracy: 0.9578 Epoch 14/20 11/11 [==============================] - 1s 105ms/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.1488 - val_accuracy: 0.9622 Epoch 15/20 11/11 [==============================] - 1s 105ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9600 Epoch 16/20 11/11 [==============================] - 1s 100ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9556 Epoch 17/20 11/11 [==============================] - 1s 100ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1480 - val_accuracy: 0.9578 Epoch 18/20 11/11 [==============================] - 1s 102ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9578 Epoch 19/20 11/11 [==============================] - 1s 102ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.1461 - val_accuracy: 0.9578 Epoch 20/20 11/11 [==============================] - 1s 101ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.1449 - val_accuracy: 0.9556 . &lt;tensorflow.python.keras.callbacks.History at 0x17045cb20&gt; . predict_y = model.predict(test_x) . np.argmax(predict_y, axis=1) == labels.values[test_range] . array([[ True, False, True, ..., False, False, False], [False, True, False, ..., False, False, False], [ True, False, True, ..., False, False, False], ..., [False, False, False, ..., True, False, True], [False, False, False, ..., False, True, False], [False, False, False, ..., True, False, True]]) . Approach 2: append new layers and freeze bottom layers of VGG for training . vgg_model = VGG16(weights=&#39;imagenet&#39;, include_top=False, input_shape=(224,224,3)) # Creating dictionary that maps layer names to the layers layer_dict = dict([(layer.name, layer) for layer in vgg_model.layers]) # Getting output tensor of the last VGG layer that we want to include x = layer_dict[&#39;block5_pool&#39;].output # Adding new layers x = Flatten()(x) x = Dense(1000, input_dim=25088, activation=&#39;relu&#39;,kernel_initializer=&#39;uniform&#39;)(x) x = keras.layers.core.Dropout(0.3, noise_shape=None, seed=None)(x) x = Dense(500,input_dim=1000,activation=&#39;sigmoid&#39;)(x) x = keras.layers.core.Dropout(0.4, noise_shape=None, seed=None)(x) x = Dense(150,input_dim=500,activation=&#39;sigmoid&#39;)(x) x = keras.layers.core.Dropout(0.2, noise_shape=None, seed=None)(x) x = Dense(units=10)(x) x = Activation(&#39;softmax&#39;)(x) # Creating new model. Please note that this is NOT a Sequential() model. from keras.models import Model custom_model = Model(inputs=vgg_model.input, outputs=x) # Make sure that the pre-trained bottom layers are not trainable for layer in custom_model.layers: if layer.name in layer_dict: layer.trainable = False # Do not forget to compile it custom_model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&quot;adam&quot;, metrics=[&#39;accuracy&#39;]) . custom_model.summary() . Model: &#34;model_9&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_23 (InputLayer) [(None, 224, 224, 3)] 0 _________________________________________________________________ block1_conv1 (Conv2D) (None, 224, 224, 64) 1792 _________________________________________________________________ block1_conv2 (Conv2D) (None, 224, 224, 64) 36928 _________________________________________________________________ block1_pool (MaxPooling2D) (None, 112, 112, 64) 0 _________________________________________________________________ block2_conv1 (Conv2D) (None, 112, 112, 128) 73856 _________________________________________________________________ block2_conv2 (Conv2D) (None, 112, 112, 128) 147584 _________________________________________________________________ block2_pool (MaxPooling2D) (None, 56, 56, 128) 0 _________________________________________________________________ block3_conv1 (Conv2D) (None, 56, 56, 256) 295168 _________________________________________________________________ block3_conv2 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_conv3 (Conv2D) (None, 56, 56, 256) 590080 _________________________________________________________________ block3_pool (MaxPooling2D) (None, 28, 28, 256) 0 _________________________________________________________________ block4_conv1 (Conv2D) (None, 28, 28, 512) 1180160 _________________________________________________________________ block4_conv2 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_conv3 (Conv2D) (None, 28, 28, 512) 2359808 _________________________________________________________________ block4_pool (MaxPooling2D) (None, 14, 14, 512) 0 _________________________________________________________________ block5_conv1 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv2 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_conv3 (Conv2D) (None, 14, 14, 512) 2359808 _________________________________________________________________ block5_pool (MaxPooling2D) (None, 7, 7, 512) 0 _________________________________________________________________ flatten_7 (Flatten) (None, 25088) 0 _________________________________________________________________ dense_37 (Dense) (None, 1000) 25089000 _________________________________________________________________ dropout_24 (Dropout) (None, 1000) 0 _________________________________________________________________ dense_38 (Dense) (None, 500) 500500 _________________________________________________________________ dropout_25 (Dropout) (None, 500) 0 _________________________________________________________________ dense_39 (Dense) (None, 150) 75150 _________________________________________________________________ dropout_26 (Dropout) (None, 150) 0 _________________________________________________________________ dense_40 (Dense) (None, 10) 1510 _________________________________________________________________ activation_8 (Activation) (None, 10) 0 ================================================================= Total params: 40,380,848 Trainable params: 25,666,160 Non-trainable params: 14,714,688 _________________________________________________________________ . Train the new model . custom_model.fit( train_img, train_y, epochs=20, batch_size=128, validation_data=(test_img,test_y), ) . Epoch 1/20 11/11 [==============================] - 122s 11s/step - loss: 2.4470 - accuracy: 0.1130 - val_loss: 2.1486 - val_accuracy: 0.2711 Epoch 2/20 11/11 [==============================] - 136s 13s/step - loss: 2.2192 - accuracy: 0.1839 - val_loss: 1.9199 - val_accuracy: 0.6311 Epoch 3/20 11/11 [==============================] - 129s 12s/step - loss: 1.9635 - accuracy: 0.3612 - val_loss: 1.4907 - val_accuracy: 0.7600 Epoch 4/20 11/11 [==============================] - 128s 12s/step - loss: 1.5639 - accuracy: 0.6354 - val_loss: 1.0121 - val_accuracy: 0.8244 Epoch 5/20 11/11 [==============================] - 128s 12s/step - loss: 1.0947 - accuracy: 0.7856 - val_loss: 0.6528 - val_accuracy: 0.8978 Epoch 6/20 11/11 [==============================] - 618s 61s/step - loss: 0.7248 - accuracy: 0.8800 - val_loss: 0.4142 - val_accuracy: 0.9244 Epoch 7/20 11/11 [==============================] - 124s 12s/step - loss: 0.4343 - accuracy: 0.9431 - val_loss: 0.3164 - val_accuracy: 0.9244 Epoch 8/20 11/11 [==============================] - 127s 12s/step - loss: 0.2650 - accuracy: 0.9688 - val_loss: 0.2276 - val_accuracy: 0.9467 Epoch 9/20 11/11 [==============================] - 132s 12s/step - loss: 0.1566 - accuracy: 0.9865 - val_loss: 0.1752 - val_accuracy: 0.9600 Epoch 10/20 11/11 [==============================] - 146s 13s/step - loss: 0.1018 - accuracy: 0.9874 - val_loss: 0.2028 - val_accuracy: 0.9511 Epoch 11/20 11/11 [==============================] - 138s 13s/step - loss: 0.0771 - accuracy: 0.9946 - val_loss: 0.1748 - val_accuracy: 0.9511 Epoch 12/20 11/11 [==============================] - 137s 13s/step - loss: 0.0557 - accuracy: 0.9978 - val_loss: 0.1440 - val_accuracy: 0.9600 Epoch 13/20 11/11 [==============================] - 137s 13s/step - loss: 0.0375 - accuracy: 1.0000 - val_loss: 0.1549 - val_accuracy: 0.9533 Epoch 14/20 11/11 [==============================] - 132s 12s/step - loss: 0.0300 - accuracy: 0.9993 - val_loss: 0.1574 - val_accuracy: 0.9578 Epoch 15/20 11/11 [==============================] - 132s 12s/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9511 Epoch 16/20 11/11 [==============================] - 132s 12s/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 0.1399 - val_accuracy: 0.9578 Epoch 17/20 11/11 [==============================] - 133s 12s/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9600 Epoch 18/20 11/11 [==============================] - 133s 12s/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 0.1463 - val_accuracy: 0.9489 Epoch 19/20 11/11 [==============================] - 131s 12s/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9578 Epoch 20/20 11/11 [==============================] - 126s 12s/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.1502 - val_accuracy: 0.9556 . &lt;tensorflow.python.keras.callbacks.History at 0x1741d5160&gt; . custom_model.save(&quot;mnist/custom_model.h5&quot;, save_format=&quot;h5&quot;) . custom_model = keras.models.load_model(&quot;mnist/custom_model.h5&quot;) . import matplotlib.pyplot as plt examples = [4, 150, 1500, 1689] for ex in examples: im = image.load_img( Path.joinpath(img_path, f&quot;{ex}.png&quot;).as_posix(), target_size=(224,224) ) plt.figure() plt.imshow(im) plt.show() y = custom_model.predict(np.array([image.img_to_array(im)])) print(np.argmax(y)) print(&quot;&quot;) . 4 . 0 . 1 . 2 .",
            "url": "https://ycouble.github.io/til/en/ml/raw/2021/02/17/transfer_learning.html",
            "relUrl": "/en/ml/raw/2021/02/17/transfer_learning.html",
            "date": " • Feb 17, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Interpretability (Part 3)",
            "content": "Some quotations . A change in a feature by one unit changes the odds ratio (multiplicative) by a factor of exp(βj). We could also interpret it this way: A change in xj by one unit increases the log odds ratio by the value of the corresponding weight. . These are the interpretations for the logistic regression model with different feature types: . Numerical feature: If you increase the value of feature xj by one unit, the estimated odds change by a factor of exp(βj) | Binary categorical feature: One of the two values of the feature is the reference category (in some languages, the one encoded in 0). Changing the feature xj from the reference category to the other category changes the estimated odds by a factor of exp(βj). | Categorical feature with more than two categories: One solution to deal with multiple categories is one-hot-encoding, meaning that each category has its own column. You only need L-1 columns for a categorical feature with L categories, otherwise it is over-parameterized. The L-th category is then the reference category. You can use any other encoding that can be used in linear regression. The interpretation for each category then is equivalent to the interpretation of binary features. | Intercept β0: When all numerical features are zero and the categorical features are at the reference category, the estimated odds are exp(β0). The interpretation of the intercept weight is usually not relevant. | . Another disadvantage of the logistic regression model is that the interpretation is more difficult because the interpretation of the weights is multiplicative and not additive. . On the good side, the logistic regression model is not only a classification model, but also gives you probabilities. This is a big advantage over models that can only provide the final classification. Knowing that an instance has a 99% probability for a class compared to 51% makes a big difference. .",
            "url": "https://ycouble.github.io/til/xai/en/ml/2020/12/04/interpretability_chapter12_interpretable_models_logistic_regression.html",
            "relUrl": "/xai/en/ml/2020/12/04/interpretability_chapter12_interpretable_models_logistic_regression.html",
            "date": " • Dec 4, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Interpretability (Part 2)",
            "content": "Interpretable Models - Linear Regression . Linear regressions are simple models, which force the output to be a linear combination of the inputs. This means that the model is additive and thus easily explainable. The weights are the explaination. . Assumptions used to compute the confidence intervals: . Linearity: forced by linear regression | Normality: the probability of the target outcome given the feature should follow a normal distribution. | Homoscedasticity: (constant variance) The variance of the error terms is assumed to be constant, which is generally not verified (variance typically often increase for large values) | Independence: assumption that each instance in independent of any other, often not verified when you have several repeated measurements. If this is not the cas you need to have specific linear regression models such as mixed effect models of GEE (//TODO). | Fixed features: inputs are considered exact and without measurement errors (always wrong, but it would be highly impractical otherwise) | Absence of multicollinearity: When two features are strongly correlated, it blurrs the importance of the two (weights could go either way, and the model would be as efficient with only one of them) | . Interpretation . Interpretation depends on the type of feature: . numerical: increase in feature –&gt; increase * weight on outcome | binary/categorical: presence/absence/selection –&gt; weight on outcome | intercept: if features are normalized and bin/cat 0 = reference –&gt; outcome of all feature at their mean | . R-squared . Another important measurement is the R-squared, which tells how much of the total variance of the target outcome is explained by the model. . Higher R-squarred is better. | R² = 1 - square sum of errors / square sum of data variance. | R² increases with the number of features, so it is better to use the adjusted R² = 1 - (1 - R²) (n-1)/(n-p-1) where p is the number of features and n the number of instances | low adjusted R² –&gt; not interpretable because it does not explain much of the variance. | . Feature importance . Importance of a feature in LR can be measured by the absolute value of its T-statistic, which is the estimated weight scaled with its standard error. (standard error = standard deviation of the outcome in a outcome = intercept + feature_weight * feature_value function) . –&gt; possible to plot for each feature (like a facet plot) the y = i + w*x curve, with standard error shown, which highlights the distribution of the ground truths around the predictions. . Visual interpretation . Weight plots (https://christophm.github.io/interpretable-ml-book/limo.html#weight-plot) . Weight plots show for each feature the weight estimate and the standard error. . Low SE represents a reliable feature | High weight estimate means a high influence in the outcome | Scaling makes the estimate weights more comparable | . Effect plots . Box plots for each feature. Only effects are represented. Effect = weight * value. . vertical line = effect of the median | box = 25% and 75% quantiles effect | horizontal line = span +- 1.5 InnerQuartileRange | dots = outliers | . Explain individual predictions . Position the individual feature effects on an Effect plot: it enables to see how and why the outcome was decided (in particular, outlier effects are interesting) | . Encoding Categorical Features . Two encoding presented: . Treatment coding: N - 1 features for N categories, 1 hot encoding | Effect coding: Compare each category to the mean and use this value for encoding (only N-1 categories encoded) | . Do Linear models create good explanations ? . “linear models do not create the best explanations” . Contrastive, but the reference instance is a data point where all numerical are 0 and categorical are at their reference category (usually meaningless). If all features are mean centered, and cat features are effect coded, then the reference instance is the point where all features are at the mean. | Selectivity can be achieved by LR using less features or training sparse linear models, but by default, explainations are not selective. | Truthfulness: yes as long as the Linear Model is appropriate (aR² high). | Linearity makes the explanation mode general and simple | . Sparse Linear Models . Regularization makes the model more frugal. . By adding a lambda * norm of the weights, in the minimization term, it penalizes models that have a lot of non null weights. The higher the lambda, the less feature are going into the model. | Usually, lambda is tuned during cross-validation | | .",
            "url": "https://ycouble.github.io/til/xai/en/ml/2020/12/02/interpretability_chapter11_interpretable_models_linear_reg.html",
            "relUrl": "/xai/en/ml/2020/12/02/interpretability_chapter11_interpretable_models_linear_reg.html",
            "date": " • Dec 2, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Interpretability (Part 1)",
            "content": "Interpretable Machine Learning . Some notes on the small book Interpretable Machine Learning by Christoph Molnar. . Introduction and overview . Christoph Molnar overviews in his book the concept of model interpretability, and surveys several ways to help ML engineers design more interpretable machine learning model, i.e. enable humans to understand the reasons why the ML model outputs what it outputs instead of any the other possible answers. The motivation for model interpretability is qui immediate, as a matter of fact it is often observed that results from a recommender system such as YouTube video recommendations are somewhat obsucre, and the more importance machine learning algorithms take into our lives, the more important it will be that we are able to understand the “whys” of the ML models decisions. . Efforts are being made by many of the major actors, as for example Amazon’s recommendation systems providing a set of articles that are commonly bought together, or the “customers that bought what you just bought also often purchased this other article” and such. However, it is far from being widespread, and it also has an important impact for many many companies or labs that usually focus on ML model performance and trust almost blindly the output of their model. Note that this is not only applicable to ML, it is also often the case for sufficiently complicated models and algorithms such are optimization (among which discrete optimization is probably a great candidate), where we are unable to track or get an intuition of why the result is such and not something completely different. . The consequences of bad model interpretability are numerous, but I see one very important point, which is functional model debugging failures. If you trust you model/algorithm blindly, it then becomes very hard to see if the model behaves as it should. For example, imagine that you have a discrete optimization problem, which is NP-hard and that you solve using a custom algorithm. Since the problem is too complex, it is nearly impossible (or too long) to know the optimal solution for a large instance, and you are left with trusting your algorithm or only confronting your algorithm to the known optimal on very small instances that may not be representative of larger instances, and certainly not a proof. In this kind of situations, it becomes very important to have some other ways of checking the result of your algorithm, its consistency, why the result on such instance is much lower than on other similar instances, etc. . The same applies to machine learning, with an even more critical factor which is that ML models are much more obscure on their internal mechanisms. Indeed, unlike instruction-based algorithms which are easily probed and for which each step bears meaning, machine learning models internal steps bear no meaning and are only the result of the model training on data. . Model interpretability . What the author defines as interpretability is the capacity of a model/solution to justify its output. First he mentions that there are models that are intrinsincly interpretables sur as linear regressions, decisions trees and such where the internal parameter values already offers a sufficiently good explanation of the output. For example, for a linear regression, the weights of each feature will tell us how important are each feature compared to the others. . But for more sophisticated model, interpretability is obtained through more indirect or approximation methods, among which: . Partial dependance plots (WIP) | Individual Conditional Expectations (WIP) | Accumulated Local Effects (WIP) | Feature Interaction (WIP) | Feature Importance (WIP) | Global Surrogate, which consist of approximating the output of the model by a simple, intepretable machine learning model. | Local Surrogate, which is the same as global but only for the neighborhood of an instance. | Shapley Values, inspired from game-theory where the relative importance of each feature in the “coalition” is derived from similar instances in the dataset. | . Interpretability evaluation . Interpretability is not easily evaluated since there is no quantification of interpretability and since it depends largely on the social and technological context of the recipient of explanations. Obviously the explaination of the model output will not be the same for an field expert and for the end customer of a recommender system. . Several criteria of evaluation are underline in the book, first as general criteria for an explanation method, then for individual explanation produced by such methods: . Explanation power: how expressive the provided explanations are (do they use natural language, if-then-else type conditions…) | Translucency: how related to the model internal is the explanation (for example an explanation consisting in the weights for a linear model is a very translucent explanation) | Portability: how tied to a model is the explanation, i.e. can it be ported to other models without modifications (in the last example, the weight is not a portable explanation) | Algorithmic complexity | . Individual explanations: . Accuracy: how fit to the data is the explanation | Fidelity: how fit to the model output is the explanation | Consistency: how robust to a model change is the explanation (closely related to the method portability) | Stability (Always desirable): how robust to some small perturbations is the explanation | Comprehensibility | Certainty: how sure / confident in the explanation | Degree of Importance: feature importance for explaining the data | Novelty of the data: how exceptional is an instance compared to the known dataset | Representativeness: range covered by the explanation | . Human friendly explanations . For a model to be easily intepretable by humans the author argues that the explanations should follow several rules: . Explanations have to be selected: a good practice is to refrain from providing every possible bit of explainatory data and to limit the explanation to the 1-3 most important pieces of explanations. | Explanations should be constrastive: usually humans prefer explanations that compare the instance with similar one that have a different ouput: “why is this instance so special that it doesn’t output the same result as intuitively similar instances ?”. | Explanations should be targeted according to the target of the explanation | Explanations should focus on abnormal data whenever possible: the most important piece of explanation is not always the most numerically significant but maybe the one which bears the highest abnormality. | Explanations should be as truthful as possible, i.e. it should remain applicable on other instances and not be invalidated | If no abnormality can be found, a general and probable explanation is also preferable to many pieces of unexceptional explanations. | .",
            "url": "https://ycouble.github.io/til/xai/en/ml/2020/11/20/interpretability_chapter0.html",
            "relUrl": "/xai/en/ml/2020/11/20/interpretability_chapter0.html",
            "date": " • Nov 20, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "So you want to be a Python Expert",
            "content": "So you want to be a Python expert ? . Talk by James Powell: https://www.youtube.com/watch?v=cKPlPJyQrt4 . Topics . Python data-model | Decorators | Generators | Meta classes (not retranscripted here, he basically presented the mechanisms behind the ABC @abstractclass decorator) | Context Managers | . Python data-model . Python is entirely inspectable and has a very linear execution pattern (everything is read from top to bottom). The language makes it very easy to define operations, and to define different behaviours for any object. . class Summer: def __init__(self, *args): self.coefs = list(args) # It is possible to define a __call__ function so that the object is callable def __call__(self): return sum(self.coefs) # To be able to use built-in operators you may define these operation # with the corresponding &quot;dunder&quot; (double under) method def __add__(self, other): return Summer(*(self.coefs + other.coefs)) def __repr__(self): return (f&quot;Summer({self.coefs})&quot;) . a = Summer(1,4,5,3,10) print(a, a(), a+a, (a+a)()) . Summer([1, 4, 5, 3, 10]) 23 Summer([1, 4, 5, 3, 10, 1, 4, 5, 3, 10]) 46 . Therefore, there is very limited difference between an empty object with a __call__ method and a function. . class Adder: def __call__(self, x, y): return x + y add_obj = Adder() # Function def add(x, y): return x + y . print(add_obj, add) print(add_obj(10, 20), add(10, 20)) . &lt;__main__.Adder object at 0x104a6f5f8&gt; &lt;function add at 0x104bf12f0&gt; 30 30 . Decorators . Decorators are a syntaxic sugar of Python to define a function to wrap around any kind of function. Their main goal is to factor code and make it easier to maintain wrapping functions . def add(x, y): return x + y def sub(x, y): return x - y def mult(x, y): return x * y print(add(10, 20)) print(sub(10, 20)) print(mult(10, 20)) . 30 -10 200 . For example if you want to debug this simple code, by printing the inputs and their types before executing the function, you could put the code in each function like this: . def add(x, y): print(x, y) return x + y def sub(x, y): print(x, y) return x - y def mult(x, y): print(x, y) return x * y print(add(10, 20)) print(sub(10, 20)) print(mult(10, 20)) . 10 20 30 10 20 -10 10 20 200 . Or, you can define a function that, given a function, prints the inputs before returning the result of the function . def printer(func): def wrapper(*args): print(*args) return func(*args) return wrapper def add(x, y): return x + y add = printer(add) def sub(x, y): return x - y sub = printer(sub) def mult(x, y): return x * y mult = printer(mult) print(add(10, 20)) print(sub(10, 20)) print(mult(10, 20)) . 10 20 30 10 20 -10 10 20 200 . And then, Python provides a syntactic sugar that does exactly these add = printer(add), but more beautifully: . def printer(func): def wrapper(*args): print(*args) return func(*args) return wrapper @printer def add(x, y): return x + y @printer def sub(x, y): return x - y @printer def mult(x, y): return x * y print(add(10, 20)) print(sub(10, 20)) print(mult(10, 20)) . 10 20 30 10 20 -10 10 20 200 . Generators . Generators are essentially functions that can give the hand back to the caller in the middle of their execution. It is a way to introduce lib-level to user-level interaction. . def one_then_two(): print(&quot;first step&quot;) yield 1 print(&quot;second step&quot;) yield 2 print(&quot;third step: None&quot;) print(one_then_two) . &lt;function one_then_two at 0x104bfd378&gt; . a = one_then_two() b = next(a) print(b) b = next(a) print(b) next(a) . first step 1 second step 2 third step: None . StopIteration Traceback (most recent call last) &lt;ipython-input-10-1e40d6f632f3&gt; in &lt;module&gt;() 4 b = next(a) 5 print(b) -&gt; 6 next(a) StopIteration: . When there is no more yield statement, the generator raises a StopIteration exception to indicate it. . Generators enables bidirectional interaction with the send built-in function . a.send? . Docstring: send(arg) -&gt; send &#39;arg&#39; into generator, return next yielded value or raise StopIteration. Type: builtin_function_or_method . def lib(word): message = &quot;&quot; for _ in range(4): message = yield (message + &quot; &quot; + word) print(&quot;lib&quot;, message) def user(lib, word): message = None try: for _ in range(10): message = lib.send(message) + &quot; &quot; + word print(&quot;user&quot;, message) except StopIteration: print(&quot;the end&quot;) . ping = lib(&quot;ping&quot;) pong = user(ping, &quot;pong&quot;) . user ping pong lib ping pong user ping pong ping pong lib ping pong ping pong user ping pong ping pong ping pong lib ping pong ping pong ping pong user ping pong ping pong ping pong ping pong lib ping pong ping pong ping pong ping pong the end . Generators are also used for lazy computing: Iterating over a list of items without computing all of their values at once. It is especially useful when you may not need all of the values. . def integers(): i = 0 while True: yield i i += 1 for i in integers(): print(i) if i &gt;= 5: break . 0 1 2 3 4 5 . At all points in the above code, only one integer was kept in memory, compared with a huge (inifite) list of all integers. . Context Managers . Context managers are functions that help manage before and after steps, like opening a connection to a db, opening a file, creating a table and dropping it after etc. . def prepare(d): d[&quot;list&quot;] = [] d[&quot;dict&quot;] = {} d[&quot;description&quot;] = &quot;&quot; def destroy(d): d.pop(&quot;list&quot;) d.pop(&quot;dict&quot;) d.pop(&quot;description&quot;) def some_actions(d): d[&quot;list&quot;].append(1) d[&quot;list&quot;].append(2) d[&quot;dict&quot;][&quot;hello&quot;] = 100 d[&quot;description&quot;] = &quot;arbitrarily filled dict&quot; d = dict(a=19) prepare(d) print(d) some_actions(d) print(d) destroy(d) print(d) . {&#39;a&#39;: 19, &#39;list&#39;: [], &#39;dict&#39;: {}, &#39;description&#39;: &#39;&#39;} {&#39;a&#39;: 19, &#39;list&#39;: [1, 2], &#39;dict&#39;: {&#39;hello&#39;: 100}, &#39;description&#39;: &#39;arbitrarily filled dict&#39;} {&#39;a&#39;: 19} . To avoid doing the prepare/destroy each time you want to use the function some_action, it is possible to use a context manager, which are designed exactly for that. . A context manager is essentially an object with an __enter__ and a __exit__ method, it is called with the withstatement. . class DictManager: def __init__(self, d): self._dict = d def __enter__(self): self._dict[&quot;list&quot;] = [] self._dict[&quot;dict&quot;] = {} self._dict[&quot;description&quot;] = &quot;&quot; def __exit__(self, *args): self._dict.pop(&quot;list&quot;) self._dict.pop(&quot;dict&quot;) self._dict.pop(&quot;description&quot;) d = dict(a=19) print(d) with DictManager(d): print(d) some_actions(d) print(d) print(d) . {&#39;a&#39;: 19} {&#39;a&#39;: 19, &#39;list&#39;: [], &#39;dict&#39;: {}, &#39;description&#39;: &#39;&#39;} {&#39;a&#39;: 19, &#39;list&#39;: [1, 2], &#39;dict&#39;: {&#39;hello&#39;: 100}, &#39;description&#39;: &#39;arbitrarily filled dict&#39;} {&#39;a&#39;: 19} . And since __enter__ and __exit__ are called in order, there can be a generator that creates the sequence: . class DictManager: def __init__(self, gen): self.gen = gen def __call__(self, *args, **kwargs): self.args, self.kwargs = args, kwargs return self def __enter__(self): self.gen_inst = self.gen(*self.args, **self.kwargs) next(self.gen_inst) def __exit__(self, *args): next(self.gen_inst, None) def tempdict(d): d[&quot;list&quot;] = [] d[&quot;dict&quot;] = {} d[&quot;description&quot;] = &quot;&quot; print(&quot;init d&quot;) yield d.pop(&quot;list&quot;) d.pop(&quot;dict&quot;) d.pop(&quot;description&quot;) print(&quot;restored d&quot;) tempdict = DictManager(tempdict) d = dict(a=19) print(d) with tempdict(d): print(d) some_actions(d) print(d) print(d) . {&#39;a&#39;: 19} init d {&#39;a&#39;: 19, &#39;list&#39;: [], &#39;dict&#39;: {}, &#39;description&#39;: &#39;&#39;} {&#39;a&#39;: 19, &#39;list&#39;: [1, 2], &#39;dict&#39;: {&#39;hello&#39;: 100}, &#39;description&#39;: &#39;arbitrarily filled dict&#39;} restored d {&#39;a&#39;: 19} . And that is basically what a context manager is. There is a predefined contextmanager decorator which does this for us: . from contextlib import contextmanager @contextmanager def tempdict(d): d[&quot;list&quot;] = [] d[&quot;dict&quot;] = {} d[&quot;description&quot;] = &quot;&quot; print(&quot;init d&quot;) try: yield finally: d.pop(&quot;list&quot;) d.pop(&quot;dict&quot;) d.pop(&quot;description&quot;) print(&quot;restored d&quot;) d = dict(a=19) print(d) with tempdict(d): print(d) some_actions(d) print(d) print(d) . {&#39;a&#39;: 19} init d {&#39;a&#39;: 19, &#39;list&#39;: [], &#39;dict&#39;: {}, &#39;description&#39;: &#39;&#39;} {&#39;a&#39;: 19, &#39;list&#39;: [1, 2], &#39;dict&#39;: {&#39;hello&#39;: 100}, &#39;description&#39;: &#39;arbitrarily filled dict&#39;} restored d {&#39;a&#39;: 19} . So, in the end, all you have to do to create a proper context manager is to import the contextmanager decorator from contextlib, and put it on a function that calls yield once, surrounded preferably by a try/finally statement to always perfome the closing instructions .",
            "url": "https://ycouble.github.io/til/en/python/raw/2020/11/17/Powell-So_you_want_to_be_a_python_expert.html",
            "relUrl": "/en/python/raw/2020/11/17/Powell-So_you_want_to_be_a_python_expert.html",
            "date": " • Nov 17, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Hadoop",
            "content": "Hadoop Platform and Application Framework . Lesson 1 . Hadoop Stack: [ Clients ] &gt; [ MapReduce ] &gt; [ YARN ] &gt; [ HDFS ] . Hadoop File System: Distributed, scalable and portable file-system written in Java for the Hadoop framework replicates accross several hosts | system is composed of Namenode(s) which keep some metadata on the contained folders (e.g. name, number of replica…) and Datanodes which contain the (replicated) data blocks. | secondary namenode: scans and builds snapshots of the primary namenode (raptures information, location etc.) | A Hadoop based system always sits on some version of a MapReduce engine: | . Job/Task trackers: job tracker on the namenode (client’s job tracking) and task tracker on the datanodes (operation tracking) | MapReduceV2 -&gt; YARN (Hadoop 2.0): Separates the research management and process component (generalization of the hadoop architecture to other processing than mapreduce) | Before YARN, the hdfs stack was [ MapReduce ] &gt; [ HDFS ], now it is possible to have others data processing: [ Map Reduce | Others ] &gt; [ YARN ] &gt; [ HDFS ] - Yarns = scheduling, MapReduce (in V2) = data processing | . | The Hadoop Zoo Started from the Google FS, and incrementally added functionalities (SQL like queries, BigTable, Sawzall, …) -&gt; variations accross big tech companies, but with the same global architecture: (cloudera’s implem) [ UI Framework (hue) | SDK (hue) ] [ Workflow mgmt (oozie) | Scheduling (oozie) | Metadata (Hive) ] [ Data Integration (flume, sqoop) | [ Languages, compilers (pig/hive) ] &gt; [ Hadoop ] | Fast read/write access (hbase) ] [ Coordination (zookeeper) ] . | . | Hadoop Ecosystem Major Components PIG: | . High level programming on to for Hadoop MapReduce | Multiple languages: JPython, Java … | Data analysis problems as data flows | Pig for ETL: inport, extract, transform, write back on the hdfs [Q: difference with Beam ?] - Hive: | Facilitates queriying and managing large datasets in distributed storage | Hive QL - Oozie: | Workflow scheduler to manage Hadoop jobs | Coordinator jobs | Supports: MapReduce, Pig, Hive, Sqoop… - Zookeeper: | Provides centralized, AOM and synchronization - Flume: | Distributed, reliable and available service for collecting, aggregating and moving large amount of log data - Many others (Impala, Cloudera search, Spark, Majout, …) - Spark: | Parallel, in-memory, large scale data processing | . |",
            "url": "https://ycouble.github.io/til/en/bigdata/2020/11/02/hadoop-course-notes.html",
            "relUrl": "/en/bigdata/2020/11/02/hadoop-course-notes.html",
            "date": " • Nov 2, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ycouble.github.io/til/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ycouble.github.io/til/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ycouble.github.io/til/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ycouble.github.io/til/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}